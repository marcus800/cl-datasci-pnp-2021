{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_data(housing_path):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "housing = load_data(\"housing/\") #pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "housing[\"income_cat\"] = np.ceil(housing[\"median_income\"] / 1.5)\n",
    "\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "#splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>income_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.924515</td>\n",
       "      <td>-0.109796</td>\n",
       "      <td>0.048963</td>\n",
       "      <td>0.075583</td>\n",
       "      <td>0.107149</td>\n",
       "      <td>0.061549</td>\n",
       "      <td>-0.015589</td>\n",
       "      <td>-0.045056</td>\n",
       "      <td>-0.013558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>-0.924515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009864</td>\n",
       "      <td>-0.039721</td>\n",
       "      <td>-0.071816</td>\n",
       "      <td>-0.115095</td>\n",
       "      <td>-0.076752</td>\n",
       "      <td>-0.078979</td>\n",
       "      <td>-0.144684</td>\n",
       "      <td>-0.076783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing_median_age</th>\n",
       "      <td>-0.109796</td>\n",
       "      <td>0.009864</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.363195</td>\n",
       "      <td>-0.324448</td>\n",
       "      <td>-0.297841</td>\n",
       "      <td>-0.305708</td>\n",
       "      <td>-0.116608</td>\n",
       "      <td>0.111770</td>\n",
       "      <td>-0.113993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rooms</th>\n",
       "      <td>0.048963</td>\n",
       "      <td>-0.039721</td>\n",
       "      <td>-0.363195</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928874</td>\n",
       "      <td>0.855803</td>\n",
       "      <td>0.917204</td>\n",
       "      <td>0.203718</td>\n",
       "      <td>0.135989</td>\n",
       "      <td>0.198239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_bedrooms</th>\n",
       "      <td>0.075583</td>\n",
       "      <td>-0.071816</td>\n",
       "      <td>-0.324448</td>\n",
       "      <td>0.928874</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.876225</td>\n",
       "      <td>0.979599</td>\n",
       "      <td>-0.005800</td>\n",
       "      <td>0.049177</td>\n",
       "      <td>-0.005357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>0.107149</td>\n",
       "      <td>-0.115095</td>\n",
       "      <td>-0.297841</td>\n",
       "      <td>0.855803</td>\n",
       "      <td>0.876225</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905172</td>\n",
       "      <td>0.007472</td>\n",
       "      <td>-0.024765</td>\n",
       "      <td>0.007102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>households</th>\n",
       "      <td>0.061549</td>\n",
       "      <td>-0.076752</td>\n",
       "      <td>-0.305708</td>\n",
       "      <td>0.917204</td>\n",
       "      <td>0.979599</td>\n",
       "      <td>0.905172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014929</td>\n",
       "      <td>0.065841</td>\n",
       "      <td>0.014345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_income</th>\n",
       "      <td>-0.015589</td>\n",
       "      <td>-0.078979</td>\n",
       "      <td>-0.116608</td>\n",
       "      <td>0.203718</td>\n",
       "      <td>-0.005800</td>\n",
       "      <td>0.007472</td>\n",
       "      <td>0.014929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.687474</td>\n",
       "      <td>0.975364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_house_value</th>\n",
       "      <td>-0.045056</td>\n",
       "      <td>-0.144684</td>\n",
       "      <td>0.111770</td>\n",
       "      <td>0.135989</td>\n",
       "      <td>0.049177</td>\n",
       "      <td>-0.024765</td>\n",
       "      <td>0.065841</td>\n",
       "      <td>0.687474</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.667208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income_cat</th>\n",
       "      <td>-0.013558</td>\n",
       "      <td>-0.076783</td>\n",
       "      <td>-0.113993</td>\n",
       "      <td>0.198239</td>\n",
       "      <td>-0.005357</td>\n",
       "      <td>0.007102</td>\n",
       "      <td>0.014345</td>\n",
       "      <td>0.975364</td>\n",
       "      <td>0.667208</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    longitude  latitude  housing_median_age  total_rooms  \\\n",
       "longitude            1.000000 -0.924515           -0.109796     0.048963   \n",
       "latitude            -0.924515  1.000000            0.009864    -0.039721   \n",
       "housing_median_age  -0.109796  0.009864            1.000000    -0.363195   \n",
       "total_rooms          0.048963 -0.039721           -0.363195     1.000000   \n",
       "total_bedrooms       0.075583 -0.071816           -0.324448     0.928874   \n",
       "population           0.107149 -0.115095           -0.297841     0.855803   \n",
       "households           0.061549 -0.076752           -0.305708     0.917204   \n",
       "median_income       -0.015589 -0.078979           -0.116608     0.203718   \n",
       "median_house_value  -0.045056 -0.144684            0.111770     0.135989   \n",
       "income_cat          -0.013558 -0.076783           -0.113993     0.198239   \n",
       "\n",
       "                    total_bedrooms  population  households  median_income  \\\n",
       "longitude                 0.075583    0.107149    0.061549      -0.015589   \n",
       "latitude                 -0.071816   -0.115095   -0.076752      -0.078979   \n",
       "housing_median_age       -0.324448   -0.297841   -0.305708      -0.116608   \n",
       "total_rooms               0.928874    0.855803    0.917204       0.203718   \n",
       "total_bedrooms            1.000000    0.876225    0.979599      -0.005800   \n",
       "population                0.876225    1.000000    0.905172       0.007472   \n",
       "households                0.979599    0.905172    1.000000       0.014929   \n",
       "median_income            -0.005800    0.007472    0.014929       1.000000   \n",
       "median_house_value        0.049177   -0.024765    0.065841       0.687474   \n",
       "income_cat               -0.005357    0.007102    0.014345       0.975364   \n",
       "\n",
       "                    median_house_value  income_cat  \n",
       "longitude                    -0.045056   -0.013558  \n",
       "latitude                     -0.144684   -0.076783  \n",
       "housing_median_age            0.111770   -0.113993  \n",
       "total_rooms                   0.135989    0.198239  \n",
       "total_bedrooms                0.049177   -0.005357  \n",
       "population                   -0.024765    0.007102  \n",
       "households                    0.065841    0.014345  \n",
       "median_income                 0.687474    0.975364  \n",
       "median_house_value            1.000000    0.667208  \n",
       "income_cat                    0.667208    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = housing.corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.drop(\"median_house_value\", axis=1) #drop makes a copy!\n",
    "\n",
    "# #TO DROP LESS INFORMATIVE STUFF:\n",
    "# # housing = housing.drop(\"households\",axis=1)\n",
    "\n",
    "# housing_labels = strat_train_set[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# imputer = SimpleImputer(strategy=\"median\")\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "# imputer.fit(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = imputer.transform(housing_num)\n",
    "# housing_tr = pd.DataFrame(X, columns=housing_num.columns)\n",
    "# # housing_tr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<16512x5 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 16512 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "encoder = LabelBinarizer(sparse_output=True)\n",
    "housing_cat_1hot = encoder.fit_transform(housing[\"ocean_proximity\"])\n",
    "housing_cat_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin \n",
    "# BaseEstimator allows you to drop *args and **kwargs from you constructor\n",
    "# and, in addition, allows you to use methods set_params() and get_params()\n",
    "\n",
    "rooms_id, bedrooms_id, population_id, household_id = 3, 4, 5, 6\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_rooms = True): # note no *args and **kwargs used this time\n",
    "        self.add_bedrooms_per_rooms = add_bedrooms_per_rooms\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:, rooms_id] / X[:, household_id]\n",
    "        bedrooms_per_household = X[:, bedrooms_id] / X[:, household_id]\n",
    "        population_per_household = X[:, population_id] / X[:, household_id]\n",
    "        if self.add_bedrooms_per_rooms:\n",
    "            bedrooms_per_rooms = X[:, bedrooms_id] / X[:, rooms_id]\n",
    "            return np.c_[X, rooms_per_household, bedrooms_per_household, \n",
    "                         population_per_household, bedrooms_per_rooms]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, bedrooms_per_household, \n",
    "                         population_per_household]\n",
    "        \n",
    "attr_adder = CombinedAttributesAdder()\n",
    "housing_extra_attribs = attr_adder.transform(housing.values)\n",
    "# print(housing_extra_attribs.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# housing_tr_scaled = scaler.fit_transform(housing_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin # TransformerMixin allows you to use fit_transform method\n",
    "\n",
    "class CustomLabelBinarizer(TransformerMixin):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.encoder = LabelBinarizer(*args, **kwargs)\n",
    "    def fit(self, X, y=0):\n",
    "        self.encoder.fit(X)\n",
    "        return self\n",
    "    def transform(self, X, y=0):\n",
    "        return self.encoder.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        #('imputer', Imputer(strategy=\"median\")),\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('attribs_adder', CombinedAttributesAdder()),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(cat_attribs)),\n",
    "        ('label_binarizer', CustomLabelBinarizer()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16512, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.15788621,  0.77388697,  0.74440696, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.44259512,  1.0077626 ,  1.85708974, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 1.18471864, -1.3403487 ,  0.18806557, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [ 1.58431009, -0.72291704, -1.56043594, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.7801323 , -0.84920988,  0.18806557, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.43760023,  0.99840757,  1.85708974, ...,  0.        ,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])\n",
    "\n",
    "#trying to drop instead of imputer:\n",
    "# strat_train_set = strat_train_set.dropna(subset=[\"total_bedrooms\"]) # (16356, 17) vs  (16512, 17)\n",
    "\n",
    "\n",
    "housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(housing)\n",
    "print(housing_prepared.shape)\n",
    "housing_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   ccp_alpha=0.0,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   max_samples=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators=100,\n",
       "                                                   n_jobs=None, oob_score=False,\n",
       "                                                   random_state=None, verbose=0,\n",
       "                                                   warm_start=False),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'max_features': [2, 4, 6, 8],\n",
       "                                        'n_estimators': [3, 10, 30]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='neg_mean_squared_error',\n",
       "                   verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# specify the range of hyperparameter values for the grid search to try out \n",
    "param_grid = {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]}\n",
    "\n",
    "# NOT GOING TO USE FOREST AS TAKES TOO LONG!\n",
    "\n",
    "forest_reg = RandomForestRegressor() #here\n",
    "not_grid_search = RandomizedSearchCV(forest_reg, param_grid, cv=5,\n",
    "                          scoring=\"neg_mean_squared_error\")\n",
    "not_grid_search.fit(housing_prepared, housing_labels)\n",
    "\n",
    "# print(grid_search.best_params_)\n",
    "\n",
    "# cv_results = grid_search.cv_results_\n",
    "# for mean_score, params in zip(cv_results[\"mean_test_score\"], cv_results[\"params\"]):\n",
    "#     print(np.sqrt(-mean_score), params)\n",
    "    \n",
    "# feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "# print (feature_importances)\n",
    "\n",
    "# extra_attribs = ['rooms_per_household', 'bedrooms_per_household', 'population_per_household', 'bedrooms_per_rooms']\n",
    "# cat_one_hot_attribs = ['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN']\n",
    "# attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
    "# sorted(zip(feature_importances, attributes), reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48770.37279878371"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = not_grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# final_model = LinearRegression()\n",
    "# final_model = final_model.fit(housing_prepared, housing_labels)\n",
    "\n",
    "# print(final_model.coef_)\n",
    "\n",
    "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "y_test = strat_test_set[\"median_house_value\"].copy()\n",
    "\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers:\n",
    "- Droping households which seems to be least inforamtive increases RMSE to 49737.4001959307 so no help as expected\n",
    "- Different ideas:\n",
    "\n",
    "Droppoing na instead of imputer stuff does: 48617.15275987233, 48708.793135364955 So seems very comparible perhaps a bit worse \\\n",
    "Doing mean SimpleImputer again makes v small diffrence perhaps a bit better 48074.00229046668. \\\n",
    "Min Max scaler makes it worse: 49153.254443779806 \\\n",
    "No scalling does simular badness: 49046.138073279675 \\\n",
    "Not sure what feature scaling is, I thought that is what the scaling we are doing? \n",
    "\n",
    "- Linear regresion final_rmse\n",
    "\n",
    "Random Forest Ressonto RMSE with opt values are: 48695.78065596131, 48014.03994500478,  - seems to be different each time! \\\n",
    "But on other noteboke always get 48120.666286373504 each time! And 48100.813816646856 on other...\n",
    "\n",
    "\n",
    "Linear Regesion with defalt prametres: 67244.28825732337 so much worse\n",
    "\n",
    "- Diffrent features importance weights on SLR model.\n",
    "\n",
    "[-5.54920601e+04 -5.66388462e+04  1.40868913e+04  3.09089868e+01\n",
    "  5.81332081e+03 -4.66833873e+04  4.58323022e+04  7.86130745e+04\n",
    " -4.89297049e+03  2.83004792e+04 -2.03486060e+04  1.04776090e+03\n",
    "  2.11146876e+04 -1.83626813e+04 -5.43180051e+04  1.09710906e+05\n",
    " -2.22161753e+04 -1.48140438e+04]\n",
    " The weights for SLR\n",
    "\n",
    "Vs feature importace weights. Not sure\n",
    "\n",
    "VS feature correlation scores with the taget vaule of step 3\n",
    "\n",
    "- RandomizedSearchCV how does it compare with GridSearchCV\n",
    "\n",
    "RSCV Has 48770.37279878371 so seems to not make much of a diffrence?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Takes a long time to load any way to make it run faster and put more of my cpu to it?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
